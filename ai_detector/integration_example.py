"""
Integration Example: AI Video Preprocessing Pipeline

This example shows how to integrate the AI video preprocessing pipeline
with your existing video analysis system.
"""

import os
import tempfile
from typing import Dict, Any, Optional
from video_preprocessing import AIVideoPreprocessor, preprocess_video_for_ai_detection

class EnhancedVideoAnalyzer:
    """
    Enhanced video analyzer that combines preprocessing with ML classification.
    
    This class demonstrates how to integrate the preprocessing pipeline
    with your existing ML-based video analysis.
    """
    
    def __init__(self, ml_model_path: Optional[str] = None):
        """
        Initialize the enhanced analyzer.
        
        Args:
            ml_model_path: Path to your trained ML model
        """
        self.preprocessor = AIVideoPreprocessor()
        self.ml_model_path = ml_model_path
        
        # Initialize your ML model here
        # self.ml_model = load_model(ml_model_path) if ml_model_path else None
    
    def analyze_video_complete(self, video_path: str, user_id: str) -> Dict[str, Any]:
        """
        Complete video analysis with preprocessing and ML classification.
        
        Args:
            video_path: Path to video file
            user_id: User identifier
            
        Returns:
            Complete analysis results
        """
        # Stage 1: Preprocessing (fast detection)
        preprocessing_result = self.preprocessor.analyze_video(video_path)
        
        # Check if preprocessing found definitive AI indicators
        if preprocessing_result['final_decision'] != 'Unknown':
            # Video flagged as AI-generated by preprocessing
            return {
                'method': 'preprocessing',
                'overall_likelihood': preprocessing_result['confidence_score'] * 100,
                'analysis_results': {
                    'preprocessing': preprocessing_result,
                    'ml_analysis': None,
                    'total_frames': preprocessing_result['frames_analyzed'],
                    'processing_time': preprocessing_result['processing_time']
                },
                'processing_time': preprocessing_result['processing_time'],
                'total_frames': preprocessing_result['frames_analyzed'],
                'confidence_source': 'metadata_ocr_logo',
                'early_detection': True
            }
        
        # Stage 2: ML Classification (deeper analysis)
        # If preprocessing didn't find clear indicators, use ML model
        ml_result = self._run_ml_analysis(video_path, user_id)
        
        # Combine results
        combined_result = self._combine_results(preprocessing_result, ml_result)
        
        return combined_result
    
    def _run_ml_analysis(self, video_path: str, user_id: str) -> Dict[str, Any]:
        """
        Run ML-based analysis (placeholder for your existing ML pipeline).
        
        Args:
            video_path: Path to video file
            user_id: User identifier
            
        Returns:
            ML analysis results
        """
        # This is where you'd call your existing ML analysis
        # For now, we'll simulate it
        
        # Placeholder: Call your existing analyze_video function
        # from your main.py or wherever your ML analysis is implemented
        
        # Example integration with your existing backend:
        """
        from backend.main import analyze_video_frames_enhanced, extract_frames_ffmpeg
        
        # Extract frames for ML analysis
        temp_dir = tempfile.mkdtemp()
        frames_dir = os.path.join(temp_dir, "frames")
        frame_files = extract_frames_ffmpeg(video_path, frames_dir, fps=3.0)
        
        # Run your existing ML analysis
        ml_result = await analyze_video_frames_enhanced(frame_files, video_duration=0.0, fps=3.0)
        
        # Clean up
        shutil.rmtree(temp_dir, ignore_errors=True)
        
        return ml_result
        """
        
        # Placeholder implementation
        return {
            'overall_likelihood': 45.0,  # Example ML result
            'timestamps': [],
            'total_frames': 180,
            'processing_time': 25.0,
            'method': 'ml_classification'
        }
    
    def _combine_results(self, preprocessing_result: Dict, ml_result: Dict) -> Dict[str, Any]:
        """
        Combine preprocessing and ML results.
        
        Args:
            preprocessing_result: Results from preprocessing pipeline
            ml_result: Results from ML classification
            
        Returns:
            Combined analysis results
        """
        # Weight the results based on confidence
        preprocessing_weight = 0.3  # Preprocessing is fast but less accurate
        ml_weight = 0.7  # ML is slower but more accurate
        
        # Calculate combined likelihood
        preprocessing_likelihood = preprocessing_result.get('confidence_score', 0.0) * 100
        ml_likelihood = ml_result.get('overall_likelihood', 0.0)
        
        combined_likelihood = (
            preprocessing_likelihood * preprocessing_weight +
            ml_likelihood * ml_weight
        )
        
        # Determine final decision
        if preprocessing_result['final_decision'] != 'Unknown':
            final_method = 'preprocessing_dominant'
            confidence_source = 'metadata_ocr_logo'
        else:
            final_method = 'ml_dominant'
            confidence_source = 'deep_learning'
        
        return {
            'method': final_method,
            'overall_likelihood': combined_likelihood,
            'analysis_results': {
                'preprocessing': preprocessing_result,
                'ml_analysis': ml_result,
                'total_frames': ml_result.get('total_frames', 0),
                'processing_time': (
                    preprocessing_result.get('processing_time', 0) +
                    ml_result.get('processing_time', 0)
                ),
                'combination_weights': {
                    'preprocessing': preprocessing_weight,
                    'ml': ml_weight
                }
            },
            'processing_time': (
                preprocessing_result.get('processing_time', 0) +
                ml_result.get('processing_time', 0)
            ),
            'total_frames': ml_result.get('total_frames', 0),
            'confidence_source': confidence_source,
            'early_detection': False
        }

# Integration with FastAPI backend
def integrate_with_fastapi_backend():
    """
    Example of how to integrate with your existing FastAPI backend.
    
    Add this to your backend/main.py file.
    """
    
    integration_code = '''
# Add this import to your backend/main.py
from ai_detector.video_preprocessing import preprocess_video_for_ai_detection

# Modify your analyze_video endpoint
@app.post("/analyze-video", response_model=VideoAnalysisResult)
async def analyze_video(
    video: Optional[UploadFile] = File(None),
    video_url: Optional[str] = Form(None),
    user_id: str = Form(...)
):
    """Enhanced video analysis with preprocessing."""
    start_time = datetime.now()
    
    # ... existing code for file handling ...
    
    try:
        # NEW: Stage 1 - Preprocessing Pipeline
        print("Running preprocessing pipeline...")
        preprocessing_result = preprocess_video_for_ai_detection(video_path)
        
        # Check if preprocessing found definitive AI indicators
        if preprocessing_result['final_decision'] != 'Unknown':
            print(f"Early detection: {preprocessing_result['final_decision']}")
            
            # Return early with preprocessing results
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return VideoAnalysisResult(
                overall_likelihood=preprocessing_result['confidence_score'] * 100,
                analysis_results={
                    "method": "preprocessing",
                    "preprocessing_details": preprocessing_result,
                    "early_detection": True,
                    "processing_time": processing_time,
                    "frames_analyzed": preprocessing_result['frames_analyzed']
                },
                processing_time=processing_time,
                total_frames=preprocessing_result['frames_analyzed']
            )
        
        # Stage 2 - Continue with existing ML analysis
        print("Preprocessing inconclusive, running ML analysis...")
        
        # ... existing ML analysis code ...
        
        # Combine results in final response
        result = VideoAnalysisResult(
            overall_likelihood=analysis_results["overall_likelihood"],
            analysis_results={
                **analysis_results,
                "preprocessing_details": preprocessing_result,
                "early_detection": False
            },
            processing_time=processing_time,
            total_frames=analysis_results["total_frames"]
        )
        
        return result
        
    except Exception as e:
        # ... existing error handling ...
    '''
    
    return integration_code

# Example usage
if __name__ == "__main__":
    # Initialize enhanced analyzer
    analyzer = EnhancedVideoAnalyzer()
    
    # Example video analysis
    test_video = "path/to/test/video.mp4"
    if os.path.exists(test_video):
        result = analyzer.analyze_video_complete(test_video, "test_user")
        print("Analysis Result:")
        print(f"Method: {result['method']}")
        print(f"Overall Likelihood: {result['overall_likelihood']:.1f}%")
        print(f"Processing Time: {result['processing_time']:.2f}s")
        print(f"Early Detection: {result.get('early_detection', False)}")
    else:
        print("Test video not found.")
        print("\nTo test the integration:")
        print("1. Place a test video file in the specified path")
        print("2. Run this script")
        print("3. Check the analysis results")
        
        # Show integration code
        print("\n" + "="*50)
        print("FASTAPI INTEGRATION CODE:")
        print("="*50)
        print(integrate_with_fastapi_backend())